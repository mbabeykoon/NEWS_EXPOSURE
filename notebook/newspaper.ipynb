{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define your functions here...\n",
    "def read_data(file_path, fields):\n",
    "    \"\"\"Read data from the specified file path into a DataFrame using only the specified fields.\"\"\"\n",
    "    return pd.read_csv(file_path, quotechar='\"', sep=',', on_bad_lines='skip', usecols=fields)\n",
    "\n",
    "def prepare_population_dataframe(df_population):\n",
    "    \"\"\"Prepare and clean the population DataFrame.\"\"\"\n",
    "    df_population['County'] = df_population['Area_Name'].str.replace(' county', '', case=False).str.strip()\n",
    "    df_population_selected = df_population[df_population['Area_Name'].str.lower().str.endswith('county')]\n",
    "    df_population_selected['POP_ESTIMATE_2022'] = df_population_selected['POP_ESTIMATE_2022'].str.replace(',', '').astype(float)\n",
    "    return df_population_selected\n",
    "\n",
    "def add_geography_column(df_media, df_county):\n",
    "    \"\"\"Merge media DataFrame with county DataFrame to add Geography column.\"\"\"\n",
    "    merged_mp_df = df_media.merge(df_county, left_on=['state', 'county_name'], right_on=['New_State', 'New_County'])\n",
    "    merged_mp_df = merged_mp_df[df_media.columns.tolist() + ['Geography']]\n",
    "    return merged_mp_df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sales_volume_to_number(s):\n",
    "    \"\"\"Convert sales volume string to a number, handling ranges and non-numeric characters.\"\"\"\n",
    "    try:\n",
    "        if isinstance(s, str):\n",
    "            s = s.replace('$', '').replace(',', '').replace('_', '').strip()\n",
    "            return float(s.split(' ')[0].split('to')[0]) if 'to' in s else float(s)\n",
    "    except ValueError:\n",
    "        return None\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in your data\n",
    "fields = ['company_name','legal_name','address1','city','state','zip5','zip4','address_type_code','mail_addr_address1','mail_addr_city','mail_addr_state','mail_addr_zip5','mail_addr_zip4','mail_addr_address_type_code','county_code','county_name','cbsa','cbsa_name','dma','dma_name','latitude','longitude','census_id','census_block','census_tract','MedianIncomeCensusArea','MeanHousingCensusArea','url','naics_desc','sic2code','sic4code','sic6code','sic2desc','sic4desc','sic6desc','sic8desc','sic_division','exact_sales_volume','sales_volume','exact_number_of_employees','number_of_employees','employee_code','location_type','parent_company','parent_address','parent_city','parent_state','parent_zip','business_specialty','company_year_started','business_type','state_where_entity_formed','minority','woman','government','small','home_office','franchise','chain','site_status','zip_centroid_lat','zip_centroid_long','owner_company','owner_address','owner_city','owner_state','owner_zip','owner_country','owner_phone']\n",
    "df_newspaper = read_data('../artifacts/data/Raw/newspaper.csv', fields)\n",
    "df_county = pd.read_csv('../artifacts/data/shapefiles/county.csv')\n",
    "df_population = read_data('../artifacts/data/Raw/PopulationEstimates.csv', ['Area_Name','State', 'POP_ESTIMATE_2022'])\n",
    "\n",
    "# Prepare the population DataFrame\n",
    "df_population_prepared = prepare_population_dataframe(df_population)\n",
    "\n",
    "# Add geography column to newspaper data\n",
    "df_newspaper_with_geography = add_geography_column(df_newspaper, df_county)\n",
    "\n",
    "# Convert sales volume to numeric\n",
    "df_newspaper_with_geography['sales_volume'] = df_newspaper_with_geography['sales_volume'].apply(convert_sales_volume_to_number)\n",
    "df_newspaper_filtered = df_newspaper_with_geography.dropna(subset=['sales_volume'])\n",
    "df_newspaper_filtered = df_newspaper_filtered[df_newspaper_filtered['sales_volume'] < 1000000]\n",
    "\n",
    "# Load the shapefile as a GeoDataFrame\n",
    "df_shapefile_county = gpd.read_file('../artifacts/data/shapefiles/cb_2018_us_county_500k.shp')\n",
    "\n",
    "# Merge the shapefile GeoDataFrame with the filtered newspaper data\n",
    "\n",
    "merged_gdf = df_shapefile_county.merge(df_newspaper_filtered, left_on='AFFGEOID', right_on='Geography')\n",
    "\n",
    "\n",
    "\n",
    "# Merge the result with the prepared population DataFrame\n",
    "merged_gdf_final = merged_gdf.merge(df_population_prepared, how='left', left_on=['state', 'county_name'], right_on=['State', 'County'])\n",
    "\n",
    "# Calculate station count and news stations per 100,000 population\n",
    "merged_gdf_final['station_count'] = merged_gdf_final.groupby('AFFGEOID')['AFFGEOID'].transform('count')\n",
    "merged_gdf_final['newsstation_per_100k_pop'] = (merged_gdf_final['station_count'] / merged_gdf_final['POP_ESTIMATE_2022']) * 100000\n",
    "\n",
    "# Drop duplicates based on 'AFFGEOID'\n",
    "merged_gdf_final = merged_gdf_final.drop_duplicates(subset=['AFFGEOID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import json\n",
    "# Remove duplicates based on 'Geography'\n",
    "# merged_gdf_county_2 = merged_gdf_county_2.drop_duplicates(subset=['Geography'])\n",
    "\n",
    "# Convert GeoDataFrame to JSON for the choropleth\n",
    "json_data = merged_gdf_final.geometry.to_json()\n",
    "\n",
    "# Convert GeoJSON to dictionary (which is compatible with plotly)\n",
    "geojson = json.loads(json_data)\n",
    "\n",
    "# Replace NaN values with a placeholder (-1) for color mapping\n",
    "# merged_gdf_county['station_count'].fillna(-1, inplace=True)\n",
    "\n",
    "# Determine the range of your data\n",
    "min_value = merged_gdf_final['newsstation_per_100k_pop'].min()\n",
    "max_value = merged_gdf_final['newsstation_per_100k_pop'].max()\n",
    "\n",
    "fig = px.choropleth_mapbox(\n",
    "    merged_gdf_final,\n",
    "    geojson=geojson,\n",
    "    locations=merged_gdf_final.index,\n",
    "    color='newsstation_per_100k_pop',\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    range_color=(min_value, max_value),  # Set to the actual min and max of your data\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    zoom=3,\n",
    "    center={\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "    opacity=0.5,\n",
    "    hover_name='county_name'\n",
    ")\n",
    "\n",
    "# Save the figure to HTML\n",
    "fig.write_html('../artifacts/output/NewspaperStations_per_100k_people.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
